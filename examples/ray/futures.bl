# Challenges
# 1. Local sequence numbers. 
#    Bud Sandbox approach: agg requests into a list, assign ids to list members
#    as increments off a base. Then bump base by list length. Can get deterministic
#    by sorting list.
# 2. Need a compute thread (pool)
# 3. Scheduling policy specification: start with round-robin,
#    Scheduling qua non-deterministic arrival.
#    Perhaps a form of deferred merge? Like a boomerang rule?
# 4. Non-collection vars
# 5. Monotonic move through tables vs monotonic status in same table?
# 6. The "consuming" symmetric hashjoin, and shortcutting build of second arrival.
FutureServer(std::string address) {
  ###################
  ## Request handling: accept, respond, increment id
  ###################
  channel invoke_req(
    std::string server_addr,
    std::string client_addr,
    std::string code
  );
  channel invoke_resp(
    std::string client_addr,
    int32_t id
  );
  # would be nice if todo and pending were a single table of lattice type
  table todo(
    std::string client_addr,
    std::string code,
    int32_t id
  );
  table sequence(
    int64_t val;
  );

  # tag request with sequence number and store in todo
  accept: todo <+ cross(invoke_req, sequence).project<1,2,3>();
  
  # respond to request
  respond: invoke_resp <~ cross(invoke_req, sequence).project<1,3>();
  
  # bump the sequence number, assume only one request at a time for now.
  # following two rules should be replaced by a counter lattice increment
  increment_add: sequence <+ cross(sequence, invoke_req).map(t ```c++ {
       return std::get<0>(t)+1;
     }```);
  increment_del: sequence <- sequence;

  ###################
  ## Process computation: send to compute thread, mark pending
  ###################
  channel compute_req(
    int32_t id,
    std::string code
  );
  table pending(
    std::string client_addr,
    std::string code,
    int32_t id
  );
  # Process requests. Needs some scheduling discipline to gate rhs,
  # coupled with IDs of thread pool entries.
  do_compute: compute_req <+ todo.project<2,1>();
  make_pending_add: pending <+ todo;
  make_pending_del: todo <- todo;

  ###################
  ## Handle thread completion: remove from pending, place in done
  ###################
  channel compute_resp(
    int32_t id,
    std::string result
  );
  table done(
    std::string client_addr,
    int32_t id
    std::string result
  );

  # Note: could shortcut the done table if we get a join on waiting
  finish_compute: done <+ join<0,2>(compute_resp, pending).project<2,0,1>();
  pending_del: todo <- join<0,2>(compute_resp, pending).project<2,3,4>();

  ###################
  ## register waiting threads
  ###################
  channel wait(
    std::string client_addr,
    int32_t id
  );
  table waiting(
    std::string client_addr,
    int32_t id
  );
  # Note: could shortcut the waiting table if we get a join on done
  register_wait: waiting <= wait;

  ###################
  ## Result! Join up waiting and done, send result, delete from waiting & done
  ###################
  channel invoke_result(
    std::string client_addr,
    int32_t id,
    std::string result
  );
  send_result: invoke_result <~ join<1,1>(waiting, done).project<0,1,4>()
  clean_waiting: waiting <- join<1,1>(waiting, done).project<0,1>()
  clean_done: done <- join<1,1>(waiting, done).project<2,3,4>()
}